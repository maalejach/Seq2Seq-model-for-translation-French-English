{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RS9HU1St12OE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.datasets import TranslationDataset\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "import re \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacrebleu\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/9d/9846507837ca50ae20917f59d83b79246b8313bd19d4f5bf575ecb98132b/sacrebleu-1.4.9-py3-none-any.whl (60kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 3.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
      "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: typing in /miniconda3/lib/python3.6/site-packages (from sacrebleu) (3.6.6)\n",
      "Installing collected packages: portalocker, sacrebleu\n",
      "Successfully installed portalocker-1.7.0 sacrebleu-1.4.9\n"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-VsFByhf2mnq",
    "outputId": "0ca70cf0-7ac9-40ac-e1ff-66b5b491ad47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /miniconda3/lib/python3.6/site-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /miniconda3/lib/python3.6/site-packages/en_core_web_sm -->\n",
      "    /miniconda3/lib/python3.6/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XL6Yn3St2yaD",
    "outputId": "1e108298-1b3f-49bd-adbd-b39f0b898193"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fr_core_news_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.0.0/fr_core_news_sm-2.0.0.tar.gz#egg=fr_core_news_sm==2.0.0 in /miniconda3/lib/python3.6/site-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /miniconda3/lib/python3.6/site-packages/fr_core_news_sm -->\n",
      "    /miniconda3/lib/python3.6/site-packages/spacy/data/fr\n",
      "\n",
      "    You can now load the model via spacy.load('fr')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = \"spacy\",\n",
    "            tokenizer_language=\"en\",\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize = \"spacy\",\n",
    "            tokenizer_language=\"fr\",\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NKgDaXRu3-Q3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "import io\n",
    "import codecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "WXGfhTll2WRa"
   },
   "outputs": [],
   "source": [
    "# class modified from the original code in pytorch to be able to load the 2014 IWSLT dataset\n",
    "class IWSLT(TranslationDataset):\n",
    "    \"\"\"The IWSLT 2014 TED talk translation task\"\"\"\n",
    "\n",
    "    base_url = 'https://wit3.fbk.eu/archive/2014-01//texts/{}/{}/{}.tgz'\n",
    "    name = 'iwslt'\n",
    "    base_dirname = '{}-{}'\n",
    "\n",
    "    @classmethod\n",
    "    def splits(cls, exts, fields, root='.data',\n",
    "               train='train', validation='IWSLT14.TED.dev2010',\n",
    "               test='IWSLT14.TED.tst2011', max_len=20, **kwargs):\n",
    "        \"\"\"Create dataset objects for splits of the IWSLT dataset.\n",
    "        Arguments:\n",
    "            exts: A tuple containing the extension to path for each language.\n",
    "            fields: A tuple containing the fields that will be used for data\n",
    "                in each language.\n",
    "            root: Root dataset storage directory. Default is '.data'.\n",
    "            train: The prefix of the train data. Default: 'train'.\n",
    "            validation: The prefix of the validation data. Default: 'val'.\n",
    "            test: The prefix of the test data. Default: 'test'.\n",
    "            Remaining keyword arguments: Passed to the splits method of\n",
    "                Dataset.\n",
    "        \"\"\"\n",
    "        cls.dirname = cls.base_dirname.format(exts[0][1:], exts[1][1:])\n",
    "        cls.urls = [cls.base_url.format(exts[0][1:], exts[1][1:], cls.dirname)]\n",
    "        check = os.path.join(root, cls.name, cls.dirname)\n",
    "        path = cls.download(root, check=check)\n",
    "\n",
    "        train = '.'.join([train, cls.dirname])\n",
    "        validation = '.'.join([validation, cls.dirname])\n",
    "        if test is not None:\n",
    "            test = '.'.join([test, cls.dirname])\n",
    "\n",
    "        if not os.path.exists(os.path.join(path, train) + exts[0]):\n",
    "            cls.clean(path, exts=exts, max_len=max_len)\n",
    "\n",
    "        train_data = None if train is None else cls(\n",
    "            os.path.join(path, train), exts, fields, **kwargs)\n",
    "        val_data = None if validation is None else cls(\n",
    "            os.path.join(path, validation), exts, fields, **kwargs)\n",
    "        test_data = None if test is None else cls(\n",
    "            os.path.join(path, test), exts, fields, **kwargs)\n",
    "        return tuple(d for d in (train_data, val_data, test_data)\n",
    "                     if d is not None)\n",
    "\n",
    "    @staticmethod\n",
    "    def clean(path, exts, max_len=20, max_lines=200000, lower=True, remove_special_caracters=True):\n",
    "        for f_xml in glob.iglob(os.path.join(path, '*.xml')):\n",
    "            print(f_xml)\n",
    "            f_txt = os.path.splitext(f_xml)[0]\n",
    "            with codecs.open(f_txt, mode='w', encoding='utf-8') as fd_txt:\n",
    "                root = ET.parse(f_xml).getroot()[0]\n",
    "                for doc in root.findall('doc'):\n",
    "                    for e in doc.findall('seg'):\n",
    "                        s = e.text\n",
    "                        if lower:\n",
    "                            s = s.lower()\n",
    "                        if remove_special_caracters:\n",
    "                            s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "                            s = re.sub(r\"[\\W+\\d+]+\", r\" \", s)\n",
    "                        fd_txt.write(s.strip() + '\\n')\n",
    "\n",
    "        xml_tags = ['<url', '<keywords', '<talkid', '<description',\n",
    "                    '<reviewer', '<translator', '<title', '<speaker']\n",
    "        lang_src = exts[0][1:]\n",
    "        lang_trg = exts[1][1:]\n",
    "        l_lines = []\n",
    "        train_files = [os.path.join(path, 'train.tags.en-fr.fr'),os.path.join(path, 'train.tags.en-fr.en')]\n",
    "        for nb_f,f_orig in enumerate(train_files):\n",
    "            print(f_orig)\n",
    "            lang = f_orig.split(\".\")[-1]\n",
    "            print(\"lang :\", lang)\n",
    "            f_txt = f_orig.replace('.tags', '')\n",
    "            with codecs.open(f_txt, mode='w', encoding='utf-8') as fd_txt, \\\n",
    "                    io.open(f_orig, mode='r', encoding='utf-8') as fd_orig:\n",
    "                inc=0\n",
    "                for nb_l,l in enumerate(fd_orig):\n",
    "                    if inc>max_lines:\n",
    "                        break;\n",
    "                    \n",
    "                    if nb_f==0:\n",
    "                        if len(l.split(\" \"))<=max_len:\n",
    "                            if not any(tag in l for tag in xml_tags):\n",
    "                                s = l\n",
    "                                if lower:\n",
    "                                    s = s.lower()\n",
    "                                if remove_special_caracters:\n",
    "                                    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "                                    s = re.sub(r\"[\\W+\\d+]+\", r\" \", s)\n",
    "                                fd_txt.write(s.strip() + '\\n')\n",
    "                                inc+=1\n",
    "                                l_lines.append(nb_l)\n",
    "                    else:\n",
    "                        if nb_l in l_lines:\n",
    "                            s = l\n",
    "                            if lower:\n",
    "                                s = s.lower()\n",
    "                            if remove_special_caracters:\n",
    "                                s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "                                s = re.sub(r\"[\\W+\\d+]+\", r\" \", s)\n",
    "                            fd_txt.write(s.strip() + '\\n')\n",
    "                            inc+=1\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "8ToLIjW-12O9",
    "outputId": "b7b6bb7f-d971-47f8-bcb0-454ff5b43d86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading en-fr.tgz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "en-fr.tgz: 100%|██████████| 20.9M/20.9M [00:03<00:00, 6.82MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".data/iwslt/en-fr/IWSLT14.TED.tst2011.en-fr.fr.xml\n",
      ".data/iwslt/en-fr/IWSLT14.TED.tst2010.en-fr.en.xml\n",
      ".data/iwslt/en-fr/IWSLT14.TED.tst2010.en-fr.fr.xml\n",
      ".data/iwslt/en-fr/IWSLT14.TED.tst2011.en-fr.en.xml\n",
      ".data/iwslt/en-fr/IWSLT14.TED.dev2010.en-fr.en.xml\n",
      ".data/iwslt/en-fr/IWSLT14.TED.tst2012.en-fr.fr.xml\n",
      ".data/iwslt/en-fr/IWSLT14.TED.dev2010.en-fr.fr.xml\n",
      ".data/iwslt/en-fr/IWSLT14.TED.tst2012.en-fr.en.xml\n",
      ".data/iwslt/en-fr/train.tags.en-fr.fr\n",
      "lang : fr\n",
      ".data/iwslt/en-fr/train.tags.en-fr.en\n",
      "lang : en\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = IWSLT.splits(exts = ('.en', '.fr'), \n",
    "                                                    fields = (SRC, TRG), max_len=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "_wRN9mLg5qFL",
    "outputId": "a25b77c8-35c5-4acc-94df-5ab61f843f23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length train : 141119\n",
      "length val : 887\n",
      "length test : 818\n"
     ]
    }
   ],
   "source": [
    "print(\"length train :\",len(train_data))\n",
    "print(\"length val :\",len(valid_data))\n",
    "print(\"length test :\",len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = and if you zoom in times you ll see it looks like a rug\n",
      "trg = et si vous zoomez fois vous verrez que ça ressemble à un tapis\n"
     ]
    }
   ],
   "source": [
    "example_idx = 12390\n",
    "\n",
    "src = vars(train_data.examples[example_idx])['src']\n",
    "trg = vars(train_data.examples[example_idx])['trg']\n",
    "\n",
    "print(f'src = {\" \".join(src)}')\n",
    "print(f'trg = {\" \".join(trg)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = you ve seen recently corn to ethanol is just a bad experiment\n",
      "trg = vous avez pu voir récemment que la transformation du maïs en éthanol n est rien qu une mauvaise expérience\n"
     ]
    }
   ],
   "source": [
    "example_idx = 500\n",
    "\n",
    "src = vars(valid_data.examples[example_idx])['src']\n",
    "trg = vars(valid_data.examples[example_idx])['trg']\n",
    "\n",
    "print(f'src = {\" \".join(src)}')\n",
    "print(f'trg = {\" \".join(trg)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQZlbVVK12PT"
   },
   "source": [
    "Build the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "_1AlENd612PT"
   },
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ang3dCJc12PX"
   },
   "source": [
    "Define the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "QZNJZ6RL12PY"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Azqpf12k12Pb"
   },
   "source": [
    "Create the iterators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "hFdNfQfn12Pf"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E27I3lSA12Pl"
   },
   "source": [
    "## Building the Seq2Seq Model\n",
    "\n",
    "### Encoder\n",
    "\n",
    "First, we'll build the encoder. Similar to the previous model, we only use a single layer GRU, however we now use a *bidirectional RNN*. With a bidirectional RNN, we have two RNNs in each layer. A *forward RNN* going over the embedded sentence from left to right (shown below in green), and a *backward RNN* going over the embedded sentence from right to left (teal). All we need to do in code is set `bidirectional = True` and then pass the embedded sentence to the RNN as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "8McXpO1Y12Pm"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "        \n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        \n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "                \n",
    "        #outputs = [src len, batch size, hid dim * num directions]\n",
    "        #hidden = [n layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        #outputs are always from the last layer\n",
    "        \n",
    "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
    "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
    "        \n",
    "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
    "        #  encoder RNNs fed through a linear layer\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
    "        \n",
    "        #outputs = [src len, batch size, enc hid dim * 2]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqGZA1Q212Pr"
   },
   "source": [
    "### Attention\n",
    "\n",
    "Next up is the attention layer. This will take in the previous hidden state of the decoder, $s_{t-1}$, and all of the stacked forward and backward hidden states from the encoder, $H$. The layer will output an attention vector, $a_t$, that is the length of the source sentence, each element is between 0 and 1 and the entire vector sums to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "xqmZa7ZV12Pr"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        #repeat decoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #hidden = [batch size, src len, dec hid dim]\n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
    "        \n",
    "        #energy = [batch size, src len, dec hid dim]\n",
    "\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        \n",
    "        #attention= [batch size, src len]\n",
    "        \n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m245FDcH12Pw"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "4_PhMCD412Px"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "             \n",
    "        #input = [batch size]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "        \n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "                \n",
    "        #a = [batch size, src len]\n",
    "        \n",
    "        a = a.unsqueeze(1)\n",
    "        \n",
    "        #a = [batch size, 1, src len]\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        \n",
    "        #weighted = [batch size, 1, enc hid dim * 2]\n",
    "        \n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        \n",
    "        #weighted = [1, batch size, enc hid dim * 2]\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        \n",
    "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
    "            \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        \n",
    "        #output = [seq len, batch size, dec hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
    "        \n",
    "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        #output = [1, batch size, dec hid dim]\n",
    "        #hidden = [1, batch size, dec hid dim]\n",
    "        #this also means that output == hidden\n",
    "        assert (output == hidden).all()\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden.squeeze(0), a.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TFnQGYm12P3"
   },
   "source": [
    "### Seq2Seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "3QL231FP12P4"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
    "        \n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "                \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden state and all encoder hidden states\n",
    "            #receive output tensor (predictions) and new hidden state\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tW47J7m812P7"
   },
   "source": [
    "## Training the Seq2Seq Model\n",
    "\n",
    "We initialise our parameters, encoder, decoder and seq2seq model (placing it on the GPU if we have one). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "0rGoBD7R12P8"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "ENC_HID_DIM = 256\n",
    "DEC_HID_DIM = 256\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aA9JfRc12QQ"
   },
   "source": [
    "We use a simplified version of the weight initialization scheme used in the paper. Here, we will initialize all biases to zero and all weights from $\\mathcal{N}(0, 0.01)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "qu9HS84l12QR",
    "outputId": "d672d926-97e4-439b-a763-f232006722e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(23342, 128)\n",
       "    (rnn): GRU(128, 256, bidirectional=True)\n",
       "    (fc): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=768, out_features=256, bias=True)\n",
       "      (v): Linear(in_features=256, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(29362, 128)\n",
       "    (rnn): GRU(640, 256)\n",
       "    (fc_out): Linear(in_features=896, out_features=29362, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vTISYkC12Qb"
   },
   "source": [
    "Calculate the number of parameters. We get an increase of almost 50% in the amount of parameters from the last model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 34,694,834 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbCZO5El12Ql"
   },
   "source": [
    "We create an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "1cCnl9tD12Qn"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nYgQXWu12Qs"
   },
   "source": [
    "We initialize the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "LtVrozdL12Qs"
   },
   "outputs": [],
   "source": [
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IISMKUE912Qv"
   },
   "source": [
    "We then create the training loop..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "0Y-EtT3h12Qw"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2RwYodK12Q3"
   },
   "source": [
    "...and the evaluation loop, remembering to set the model to `eval` mode and turn off teaching forcing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "cDn3pZYc12Q4"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TESvDWs12Q6"
   },
   "source": [
    "Finally, define a timing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "AiIzcQyZ12Q6"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RliGlleJ12RC"
   },
   "source": [
    "Then, we train our model, saving the parameters that give us the best validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "EkXycAi412RC",
    "outputId": "91440f0c-9343-4cd1-802f-be6be2517ebf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 10m 48s\n",
      "\tTrain Loss: 6.173 | Train PPL: 479.593\n",
      "\t Val. Loss: 6.428 |  Val. PPL: 618.851\n",
      "Epoch: 02 | Time: 10m 48s\n",
      "\tTrain Loss: 5.218 | Train PPL: 184.525\n",
      "\t Val. Loss: 5.900 |  Val. PPL: 364.955\n",
      "Epoch: 03 | Time: 10m 47s\n",
      "\tTrain Loss: 4.399 | Train PPL:  81.375\n",
      "\t Val. Loss: 5.719 |  Val. PPL: 304.658\n",
      "Epoch: 04 | Time: 10m 49s\n",
      "\tTrain Loss: 3.829 | Train PPL:  46.028\n",
      "\t Val. Loss: 5.598 |  Val. PPL: 269.975\n",
      "Epoch: 05 | Time: 10m 46s\n",
      "\tTrain Loss: 3.461 | Train PPL:  31.847\n",
      "\t Val. Loss: 5.588 |  Val. PPL: 267.085\n",
      "Epoch: 06 | Time: 10m 47s\n",
      "\tTrain Loss: 3.185 | Train PPL:  24.177\n",
      "\t Val. Loss: 5.527 |  Val. PPL: 251.334\n",
      "Epoch: 07 | Time: 10m 47s\n",
      "\tTrain Loss: 2.969 | Train PPL:  19.464\n",
      "\t Val. Loss: 5.635 |  Val. PPL: 280.164\n",
      "Epoch: 08 | Time: 10m 47s\n",
      "\tTrain Loss: 2.817 | Train PPL:  16.722\n",
      "\t Val. Loss: 5.605 |  Val. PPL: 271.697\n",
      "Epoch: 09 | Time: 10m 49s\n",
      "\tTrain Loss: 2.692 | Train PPL:  14.766\n",
      "\t Val. Loss: 5.609 |  Val. PPL: 272.798\n",
      "Epoch: 10 | Time: 10m 47s\n",
      "\tTrain Loss: 2.588 | Train PPL:  13.305\n",
      "\t Val. Loss: 5.638 |  Val. PPL: 280.900\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss_list.append(valid_loss)\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'en_fr-translation_model1.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_list = [6.173, 5.218, 4.399, 3.829, 3.461, 3.185, 2.969, 2.817, 2.692, 2.588]\n",
    "val_loss_list = [6.428, 5.900, 5.719, 5.598, 5.588, 5.527, 5.635, 5.605, 5.609, 5.638]\n",
    "plt.plot(train_loss_list, label=\"train loss\")\n",
    "plt.plot(val_loss_list, label=\"validation loss\")\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUIIkJf_12RG"
   },
   "source": [
    "Finally, we test the model on the test set using these \"best\" parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "1khPL9aV12RH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 4.636 | Test PPL: 103.093 |\n"
     ]
    }
   ],
   "source": [
    "if device==torch.device(\"cuda\"):\n",
    "    model.load_state_dict(torch.load('en_fr-translation_model1.pt'))\n",
    "else:\n",
    "    model.load_state_dict(torch.load('en_fr-translation_model1.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvLpkSKk8QG1"
   },
   "source": [
    "# Inference :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TJImPKu8hKt"
   },
   "source": [
    "## Greedy decoding :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "kV0MLk5B7931"
   },
   "outputs": [],
   "source": [
    "def translate_sentence_greedy(sentence, src_field, trg_field, model, device, max_len = 50):\n",
    "\n",
    "    model.eval()\n",
    "        \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('en')\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "        \n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    \n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor)\n",
    "\n",
    "        \n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "\n",
    "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
    "    \n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        with torch.no_grad():\n",
    "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs)\n",
    "\n",
    "        attentions[i] = attention\n",
    "            \n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "KTDu5GzB8chE"
   },
   "outputs": [],
   "source": [
    "def display_attention(sentence, translation, attention):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
    "    \n",
    "    cax = ax.matshow(attention, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    ax.tick_params(labelsize=15)\n",
    "    ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
    "                       rotation=45)\n",
    "    ax.set_yticklabels(['']+translation)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Ouh9OUXk8eom"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = why should it work and is this something to do with human beings\n",
      "trg = pourquoi ça devrait marcher et est ce que cela a à voir avec les êtres humains\n",
      "predicted trg = pourquoi devrions ce travail et c est quelque chose avec les humains humains <eos>\n",
      "\n",
      "\n",
      "src = well one line of thinking is let s take this profit and redeploy it into social problems\n",
      "trg = eh bien une façon de voir les choses consiste à dire prenons ce bénéfice et redéployons le vers les problèmes sociaux\n",
      "predicted trg = eh bien une question de pensée est est ce que nous <unk> et ce et et les problèmes sociaux <eos>\n",
      "\n",
      "\n",
      "src = so this cyber sea which we know endlessly is the fundamental piece of radical openness is very much under threat as well\n",
      "trg = cette cyber mer dont nous savons sans cesse qu elle est la pièce fondamentale de la transparence radicale est donc vraiment menacée aussi\n",
      "predicted trg = donc ce mer de ce que nous savons est est est le élément de l radicale radicale est très bien <eos>\n",
      "\n",
      "\n",
      "src = i m talking about people taking and recreating using other people s content using digital technologies to say things differently\n",
      "trg = je parle ici de gens qui prennent du contenu pour en recréer avec les techniques numériques pour dire les choses différemment\n",
      "predicted trg = je parle de gens qui et et et d autres autres autres changent des technologies numériques numériques pour dire différemment différemment <eos>\n",
      "\n",
      "\n",
      "src = start the story with the arrows of the native americans and not with the arrival of the british and you have an entirely different story\n",
      "trg = commencez l histoire par les flèches des américains natifs et non par l arrivée des anglais et vous obtiendrez une histoire complètement différente\n",
      "predicted trg = commencez à l histoire avec les flèches des américains américains et pas avec le le tsunami et vous avez une histoire complètement différente <eos>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l = random.sample(range(len(train_data)), 5)\n",
    "\n",
    "for example_idx in l:\n",
    "    src = vars(train_data.examples[example_idx])['src']\n",
    "    trg = vars(train_data.examples[example_idx])['trg']\n",
    "    translation, attentiaon = translate_sentence_greedy(src, SRC, TRG, model, device)\n",
    "\n",
    "    print(f'src = {\" \".join(src)}')\n",
    "    print(f'trg = {\" \".join(trg)}')\n",
    "    print(f'predicted trg = {\" \".join(translation)}')\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "_b6oP_HC8rAY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = and it s very much an in the moment activity that they re engaged in\n",
      "trg = et ils sont vraiment plongés dans une activité spontanée\n"
     ]
    }
   ],
   "source": [
    "example_idx = 210\n",
    "\n",
    "src = vars(train_data.examples[example_idx])['src']\n",
    "trg = vars(train_data.examples[example_idx])['trg']\n",
    "\n",
    "print(f'src = {\" \".join(src)}')\n",
    "print(f'trg = {\" \".join(trg)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "FCoQYoK488_s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted trg = et c est très dans dans l activité dans laquelle l on s intéressent <eos>\n"
     ]
    }
   ],
   "source": [
    "translation, attentiaon = translate_sentence_greedy(src, SRC, TRG, model, device)\n",
    "\n",
    "print(f'predicted trg = {\" \".join(translation)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_attention(src, translation, attentiaon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = you know i never thought that i d end up working at microsoft\n",
      "trg = vous savez je n aurais jamais cru que je finirais par travailler chez microsoft\n",
      "predicted trg = vous savez je ne pensais jamais pensé que je commençais à microsoft <eos>\n",
      "\n",
      "\n",
      "src = he doesn t have a piece of paper he doesn t have a pencil he doesn t have a tape recorder\n",
      "trg = il n avait pas de papier pas de crayon il n avait pas de dictaphone\n",
      "predicted trg = il n a pas un morceau de papier il n a pas un crayon il n a pas un un de <eos>\n",
      "\n",
      "\n",
      "src = and as these tools become more physical more aware of their motion aware of each other and aware of the nuance of how we move them we can start to explore some new and fun interaction styles\n",
      "trg = a mesure que ces outils deviennent de plus en plus physiques davantage conscients de leur mouvement de la présence des autres et conscients des nuances dans notre façon de les déplacer on peut commencer à étudier de nouveaux styles d interactions amusants\n",
      "predicted trg = et ces outils deviennent plus plus plus de de leurs sens et l esprit de comment nous nous nous nous commencer à explorer une nouvelle et et de <eos>\n",
      "\n",
      "\n",
      "src = now this level of intuition becomes very important\n",
      "trg = ce niveau d intuition devient primordial\n",
      "predicted trg = maintenant ce niveau de vue devient très important <eos>\n",
      "\n",
      "\n",
      "src = this drying around the world has lead to a dramatic increase in fires\n",
      "trg = cet assèchement global a causé une hausse spectaculaire du nombre d incendies cet assèchement global a causé une hausse spectaculaire du nombre d incendies\n",
      "predicted trg = ce sédiment autour du monde a conduit à un un radical <eos>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l = random.sample(range(len(valid_data)), 5)\n",
    "\n",
    "for example_idx in l:\n",
    "    src = vars(valid_data.examples[example_idx])['src']\n",
    "    trg = vars(valid_data.examples[example_idx])['trg']\n",
    "    translation, attentiaon = translate_sentence_greedy(src, SRC, TRG, model, device)\n",
    "\n",
    "    print(f'src = {\" \".join(src)}')\n",
    "    print(f'trg = {\" \".join(trg)}')\n",
    "    print(f'predicted trg = {\" \".join(translation)}')\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLUE SCORE\n",
    "\n",
    "Previously we have only cared about the loss/perplexity of the model. However there metrics that are specifically designed for measuring the quality of a translation - the most popular is BLEU. Without going into too much detail, BLEU looks at the overlap in the predicted and actual target sequences in terms of their n-grams. It will give us a number between 0 and 1 for each sequence, where 1 means there is perfect overlap, i.e. a perfect translation, although is usually shown between 0 and 100. BLEU was designed for multiple candidate translations per source sequence, however in this dataset we only have one candidate per source.\n",
    "\n",
    "We define a calculate_bleu function which calculates the BLEU score over a provided target dataset. This function creates a corpus of the actual and predicted translation for each source sentence and then calculates the BLEU score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "\n",
    "def calculate_bleu_greedy(data, model, SRC, TRG, device):\n",
    "    \n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        src = vars(data.examples[i])['src']\n",
    "        trg = vars(data.examples[i])['trg']\n",
    "        output_words, attention = translate_sentence_greedy(src, SRC, TRG, model, device)\n",
    "        #cut off <eos> token\n",
    "        pred_trg = output_words[:-1]\n",
    "        pred_trg_sentence = ' '.join(pred_trg)\n",
    "        pred_trgs.append(pred_trg_sentence)\n",
    "        trgs.append(\" \".join(trg))\n",
    "    \n",
    "    bleu = sacrebleu.corpus_bleu(pred_trgs, [trgs])\n",
    "\n",
    "    return bleu.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.65783110863191"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_bleu_greedy(valid_data, model, SRC, TRG, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.98376106679149"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_bleu_greedy(test_data, model, SRC, TRG, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEAM SEARCH + Length normalisation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import PriorityQueue\n",
    "import operator\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, length_normalisation):\n",
    "\n",
    "        if length_normalisation:\n",
    "            return self.logp / float(self.leng)\n",
    "        else:\n",
    "            return self.logp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def beam_decode(model, sentence, src_field, trg_field, length_normalisation=True, beam_width=10, topk=1 ):\n",
    "    '''\n",
    "    :param target_tensor: target indexes tensor of shape [B, T] where B is the batch size and T is the maximum length of the output sentence\n",
    "    :param decoder_hidden: input tensor of shape [1, B, H] for start of the decoding\n",
    "    :param encoder_outputs: if you are using attention mechanism you can pass encoder outputs, [T, B, H] where T is the maximum length of input sentence\n",
    "    :param beam_widh : the width of the beam search\n",
    "    :param topk : how many sentence do you want to generate\n",
    "    :return: decoded_batch\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "        \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('en')\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "        \n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    \n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor)\n",
    "\n",
    "       \n",
    "    decoder_input = torch.LongTensor([trg_field.vocab.stoi[trg_field.init_token]]).to(device)\n",
    "    # Number of sentence to generate\n",
    "    endnodes = []\n",
    "    number_required = min((topk + 1), topk - len(endnodes))\n",
    "\n",
    "    # starting node -  hidden vector, previous node, word id, logp, length\n",
    "    node = BeamSearchNode(hidden, None, decoder_input, 0, 1)\n",
    "    nodes = PriorityQueue()\n",
    "\n",
    "    # start the queue\n",
    "    nodes.put((-node.eval(length_normalisation=length_normalisation), node))\n",
    "    qsize = 1\n",
    "    \n",
    "    # start beam search\n",
    "    while True:\n",
    "        # give up when decoding takes too long\n",
    "        if qsize > 2000: break\n",
    "\n",
    "        # fetch the best node\n",
    "        score, n = nodes.get()\n",
    "        decoder_input = n.wordid\n",
    "        decoder_hidden = n.h\n",
    "\n",
    "        if n.wordid.item() == trg_field.vocab.stoi[trg_field.eos_token] and n.prevNode != None:\n",
    "            endnodes.append((score, n))\n",
    "            # if we reached maximum # of sentences required\n",
    "            if len(endnodes) >= number_required:\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # decode for one step using decoder\n",
    "        with torch.no_grad():\n",
    "            decoder_output, decoder_hidden, attention = model.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        #decoder_output, decoder_hidden = model.decoder(decoder_input, decoder_hidden.squeeze(0), encoder_output)\n",
    "\n",
    "        # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "        log_prob, indexes = torch.topk(decoder_output, beam_width)\n",
    "        nextnodes = []\n",
    "\n",
    "        for new_k in range(beam_width):\n",
    "            decoded_t = indexes[0][new_k].view(1)\n",
    "            log_p = log_prob[0][new_k].item()\n",
    "\n",
    "            node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "            score = -node.eval(length_normalisation=length_normalisation)\n",
    "            nextnodes.append((score, node))\n",
    "\n",
    "        # put them into queue\n",
    "        for i in range(len(nextnodes)):\n",
    "            score, nn = nextnodes[i]\n",
    "            nodes.put((score, nn))\n",
    "            # increase qsize\n",
    "        qsize += len(nextnodes) - 1\n",
    "\n",
    "    # choose nbest paths, back trace them\n",
    "    if len(endnodes) == 0:\n",
    "        endnodes = [nodes.get() for _ in range(topk)]\n",
    "\n",
    "    n_best_sentences = []\n",
    "    for score, n in sorted(endnodes, key=operator.itemgetter(0)):\n",
    "        decoded_sentence_idx = []\n",
    "        decoded_sentence_idx.append(n.wordid.item())\n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            decoded_sentence_idx.append(n.wordid.item())\n",
    "\n",
    "        decoded_sentence_idx = decoded_sentence_idx[::-1]\n",
    "        decoded_sentence = [trg_field.vocab.itos[i] for i in decoded_sentence_idx]\n",
    "        n_best_sentences.append(decoded_sentence[1:])\n",
    "\n",
    "    return n_best_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source sentence :  so what does the happiest man in the world look like\n",
      "target sentence :  alors à quoi ressemble l homme le plus heureux du monde\n",
      "beam search decoded sentence :  donc que est le plus heureux du monde ressemble à monde <eos>\n",
      "greedy decoded sentence :  donc que est le plus heureux de monde monde ressemble à monde <eos>\n",
      "\n",
      "\n",
      "source sentence :  and that animated graphics can make a difference\n",
      "target sentence :  et je vous ai dit que les graphiques animés peuvent faire la différence\n",
      "beam search decoded sentence :  et ce tableau graphiques peut peut faire une différence <eos>\n",
      "greedy decoded sentence :  et ce tableau graphiques peut peut faire une différence <eos>\n",
      "\n",
      "\n",
      "source sentence :  this is a deep question\n",
      "target sentence :  c est une question profonde\n",
      "beam search decoded sentence :  c est une question question <eos>\n",
      "greedy decoded sentence :  c est une question question <eos>\n",
      "\n",
      "\n",
      "source sentence :  i had an explosion\n",
      "target sentence :  j avais provoqué une explosion\n",
      "beam search decoded sentence :  j avais une explosion <eos>\n",
      "greedy decoded sentence :  j avais une explosion <eos>\n",
      "\n",
      "\n",
      "source sentence :  and his neighbor steals one of his dung pellets\n",
      "target sentence :  et ce voisin lui vole une de ses boulettes de bouse\n",
      "beam search decoded sentence :  son voisin a attrapé un vélo de ses <eos>\n",
      "greedy decoded sentence :  son voisin a attrapé un vélo de ses <eos>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l = random.sample(range(len(train_data)), 5)\n",
    "\n",
    "for example_idx in l:\n",
    "    src = vars(train_data.examples[example_idx])['src']\n",
    "    trg = vars(train_data.examples[example_idx])['trg']\n",
    "    print(\"source sentence : \",\" \".join(src))\n",
    "    print(\"target sentence : \",\" \".join(trg))\n",
    "    predicted_beam = beam_decode(model, src, SRC, TRG, length_normalisation=True, beam_width=20, topk=1)\n",
    "    predicted_greedy, _ = translate_sentence_greedy(src, SRC, TRG, model, device)\n",
    "    print(\"beam search decoded sentence : \",\" \".join(predicted_beam[0]))\n",
    "    print(\"greedy decoded sentence : \",\" \".join(predicted_greedy))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source sentence :  and by the way when i graduated from mit i thought the worst and silliest thing to do would be to go to paris for six years\n",
      "target sentence :  d ailleurs quand j ai eu mon diplôme du mit je pensais que le pire et le plus stupide aurait été d aller à paris pendant six ans\n",
      "beam search decoded sentence :  et quand quand j ai reçu du mit j j ai dit la pire\n",
      "greedy decoded sentence :  et quand quand j ai reçu du mit j ai pensé que la pire et <unk> <unk> et pour aller à paris pour sept ans <eos>\n",
      "\n",
      "\n",
      "source sentence :  and plant\n",
      "target sentence :  et le faire saluer\n",
      "beam search decoded sentence :  et les hôtes <eos>\n",
      "greedy decoded sentence :  et les hôtes <eos>\n",
      "\n",
      "\n",
      "source sentence :  i must confess there s kind of a third motivation as well\n",
      "target sentence :  je dois avouer il y a aussi une troisième motivation\n",
      "beam search decoded sentence :  je dois avouer qu il y a une sorte de motivation <eos>\n",
      "greedy decoded sentence :  je dois avouer qu il y a une sorte de troisième motivation <eos>\n",
      "\n",
      "\n",
      "source sentence :  but now we would like you to put joey through some paces\n",
      "target sentence :  mais maintenant nous aimerions que vous mettiez joey à l épreuve\n",
      "beam search decoded sentence :  mais maintenant nous aimerions qu on va prendre\n",
      "greedy decoded sentence :  mais maintenant nous aimerions que vous mettiez de voler en jouant <eos>\n",
      "\n",
      "\n",
      "source sentence :  now within our community a certain culture has appeared\n",
      "target sentence :  au sein de notre communauté une certaine culture est apparue\n",
      "beam search decoded sentence :  maintenant dans notre communauté de une culture culture <eos>\n",
      "greedy decoded sentence :  maintenant dans notre communauté de une culture a été <eos>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l = random.sample(range(len(valid_data)), 5)\n",
    "\n",
    "for example_idx in l:\n",
    "    src = vars(train_data.examples[example_idx])['src']\n",
    "    trg = vars(train_data.examples[example_idx])['trg']\n",
    "    print(\"source sentence : \",\" \".join(src))\n",
    "    print(\"target sentence : \",\" \".join(trg))\n",
    "    predicted_beam = beam_decode(model, src, SRC, TRG, length_normalisation=True, beam_width=20, topk=1)\n",
    "    predicted_greedy, _ = translate_sentence_greedy(src, SRC, TRG, model, device)\n",
    "    print(\"beam search decoded sentence : \",\" \".join(predicted_beam[0]))\n",
    "    print(\"greedy decoded sentence : \",\" \".join(predicted_greedy))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "def calculate_bleu_beam_search(data, model, SRC, TRG, device, length_normalisation=True, beam_width=20):\n",
    "    \n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        src = vars(data.examples[i])['src']\n",
    "        #print(src)\n",
    "        trg = vars(data.examples[i])['trg']\n",
    "        try :\n",
    "            output_words = beam_decode(model, src, SRC, TRG, length_normalisation=length_normalisation, \n",
    "                                       beam_width=beam_width, topk=1)\n",
    "            pred_trg = output_words[0][:-1]\n",
    "            #print(pred_trg)\n",
    "            pred_trg_sentence = ' '.join(pred_trg)\n",
    "            pred_trgs.append(pred_trg_sentence)\n",
    "            trgs.append(\" \".join(trg))\n",
    "        except(TypeError):\n",
    "            print(\"pass due to unknown TypeError\")\n",
    "        \n",
    "    \n",
    "    bleu = sacrebleu.corpus_bleu(pred_trgs, [trgs])\n",
    "\n",
    "    return bleu.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation and test score with length penalisation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam width =  10\n",
      "bleu score = 8.83953422570629\n",
      "execution time : 529.6709139347076\n",
      "\n",
      "\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "beam width =  20\n",
      "bleu score = 8.171279421584828\n",
      "execution time : 332.4088909626007\n",
      "\n",
      "\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "beam width =  50\n",
      "bleu score = 6.860691991139817\n",
      "execution time : 180.82362031936646\n",
      "\n",
      "\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "beam width =  100\n",
      "bleu score = 5.410254378627553\n",
      "execution time : 129.20666193962097\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beam_width_list = [10,20,50,100]\n",
    "for beam_width in beam_width_list:\n",
    "    start_time = time.time()\n",
    "    s = calculate_bleu_beam_search(valid_data, model, SRC, TRG, device, length_normalisation=True, beam_width=beam_width)\n",
    "    end_time = time.time()\n",
    "    print(\"beam width = \",beam_width)\n",
    "    print(\"bleu score =\",s)\n",
    "    print(\"execution time :\",end_time-start_time)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam width =  10\n",
      "bleu score = 15.448628058694181\n",
      "execution time : 437.87719798088074\n",
      "\n",
      "\n",
      "beam width =  20\n",
      "bleu score = 14.918149412532347\n",
      "execution time : 262.2862720489502\n",
      "\n",
      "\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "beam width =  50\n",
      "bleu score = 13.345503964005122\n",
      "execution time : 144.9031901359558\n",
      "\n",
      "\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "beam width =  100\n",
      "bleu score = 11.301024687657817\n",
      "execution time : 106.8429479598999\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beam_width_list = [10,20,50,100]\n",
    "for beam_width in beam_width_list:\n",
    "    start_time = time.time()\n",
    "    s = calculate_bleu_beam_search(test_data, model, SRC, TRG, device, length_normalisation=True, beam_width=beam_width)\n",
    "    end_time = time.time()\n",
    "    print(\"beam width = \",beam_width)\n",
    "    print(\"bleu score =\",s)\n",
    "    print(\"execution time :\",end_time-start_time)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation and test score without length penalisation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam width =  10\n",
      "bleu score = 10.644855000201375\n",
      "execution time : 112.03231716156006\n",
      "\n",
      "\n",
      "pass due to unknown TypeError\n",
      "beam width =  20\n",
      "bleu score = 10.65700976630921\n",
      "execution time : 99.52241802215576\n",
      "\n",
      "\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "beam width =  50\n",
      "bleu score = 10.666781366584228\n",
      "execution time : 113.8241720199585\n",
      "\n",
      "\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "beam width =  100\n",
      "bleu score = 8.950407712786904\n",
      "execution time : 117.0206310749054\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beam_width_list = [10,20,50,100]\n",
    "for beam_width in beam_width_list:\n",
    "    start_time = time.time()\n",
    "    s = calculate_bleu_beam_search(valid_data, model, SRC, TRG, device, length_normalisation=False, beam_width=beam_width)\n",
    "    end_time = time.time()\n",
    "    print(\"beam width = \",beam_width)\n",
    "    print(\"bleu score =\",s)\n",
    "    print(\"execution time :\",end_time-start_time)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam width =  10\n",
      "bleu score = 16.933839699914913\n",
      "execution time : 89.98872113227844\n",
      "\n",
      "\n",
      "beam width =  20\n",
      "bleu score = 16.96990611340291\n",
      "execution time : 87.48685383796692\n",
      "\n",
      "\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "beam width =  50\n",
      "bleu score = 16.993190622779284\n",
      "execution time : 93.13923382759094\n",
      "\n",
      "\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "pass due to unknown TypeError\n",
      "beam width =  100\n",
      "bleu score = 15.940887078369652\n",
      "execution time : 99.37949013710022\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beam_width_list = [10,20,50,100]\n",
    "for beam_width in beam_width_list:\n",
    "    start_time = time.time()\n",
    "    s = calculate_bleu_beam_search(test_data, model, SRC, TRG, device, length_normalisation=False, beam_width=beam_width)\n",
    "    end_time = time.time()\n",
    "    print(\"beam width = \",beam_width)\n",
    "    print(\"bleu score =\",s)\n",
    "    print(\"execution time :\",end_time-start_time)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SEQ2SEQ_translation_model_TP3_P2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
